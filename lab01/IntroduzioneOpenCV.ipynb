{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "private_outputs": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Esercitazione introduttiva su OpenCV**\n",
    "Nell'esercitazione odierna verrà introdotta la *Open Source Computer Vision Library* (chiamata comunemente [**OpenCV**](https://opencv.org/)).\n",
    "\n",
    "OpenCV è una libreria multipiattaforma *open-source* scritta in C++ e utilizzata per sviluppare sistemi di visione artificiale di cui esistono interfacce (o *wrapper*) per i più comuni linguaggi di programmazione.\n",
    "\n",
    "<img src=https://biolab.csr.unibo.it/vr/esercitazioni/NotebookImages/EsIntroduzioneOpenCV\\MultiPlatformOpenCV.png width=\"800\">\n",
    "\n",
    "Algoritmi presenti all'interno di OpenCV vengono oggi utilizzati in molteplici ambiti applicativi legati alla *Computer Vision*.\n",
    "\n",
    "<img src=https://biolab.csr.unibo.it/vr/esercitazioni/NotebookImages/EsIntroduzioneOpenCV\\ApplicationAreaOpenCV.png width=\"800\">"
   ],
   "metadata": {
    "id": "wkfmCyHras9O"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Operazioni preliminari**\n",
    "Prima di incominciare, è necessario eseguire alcune operazioni preliminari.\n",
    "\n",
    "Eseguendo la cella sottostante tutto il materiale necessario per lo svolgimento dell'esercitazione verrà scaricato sulla macchina remota. Alla fine dell'esecuzione selezionare nel menù laterale **File** per verificare che tutto sia stato scaricato correttamente."
   ],
   "metadata": {
    "id": "HORM8PWbRDYV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!wget http://bias.csr.unibo.it/VR/Esercitazioni/MaterialeEsIntroduzioneOpenCV.zip\n",
    "\n",
    "!unzip -q /content/MaterialeEsIntroduzioneOpenCV.zip\n",
    "\n",
    "!rm /content/MaterialeEsIntroduzioneOpenCV.zip"
   ],
   "metadata": {
    "id": "xGt3VSGaRRVN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Import delle librerie**\n",
    "Per prima cosa è necessario eseguire l'import delle librerie utilizzate durante l'esecitazione."
   ],
   "metadata": {
    "id": "awGeLI9kc44w"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDGztYUUiu4_"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "# per problemi di compatibilità con google colab la chiamata di openCV non funzi\n",
    "# direttamente. Per farlo colab utilizza\n",
    "from google.colab.patches import cv2_imshow\n",
    "from ipywidgets import interact, fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Versione OpenCV e documentazione**\n",
    "A questo [link](https://docs.opencv.org/) si può trovare la documentazione delle varie versioni di OpenCV.\n",
    "\n",
    "L'istruzione sottostante visualizza la versione di OpenCV  presente sulla macchina virtuale Colab così da scegliere la documentazione corretta."
   ],
   "metadata": {
    "id": "SidiG2JF4--K"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print('Versione OpenCV:',cv2.__version__)"
   ],
   "metadata": {
    "id": "ed97YkJv40ab"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Immagini in OpenCV**\n",
    "OpenCV utilizza la grafica *raster* per rappresentare le immagini tramite una **matrice** di valori detti pixel (*picture element*).\n",
    "Alcune caratteristiche rilevanti:\n",
    "- dimensione ($W \\times H$);\n",
    "- risoluzione (DPI);\n",
    "- formato dei pixel (B/N, grayscale, colore).\n",
    "\n",
    "<img src=https://biolab.csr.unibo.it/vr/esercitazioni/NotebookImages/EsIntroduzioneOpenCV\\RawImages.png width=\"1200\">\n",
    "\n",
    "[**NumPy**](https://numpy.org/) è una libreria del linguaggio Python che permette di definire e manipolare vettori e matrici multidimensionali ormai diventata un punto di riferimento per via della sua facilità d'uso e del gran numero di operazioni messe a disposizione.\n",
    "\n",
    "Pertanto, in Python, OpenCV tratta le immagini come array di NumPy ([**ndarray**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html?highlight=ndarray#numpy.ndarray) - *n-dimensional array*)."
   ],
   "metadata": {
    "id": "aBuX-VAW2E3k"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Creare un'immagine grayscale**\n",
    "La cella sottostante crea un'immagine *grayscale* (con un solo canale) come una matrice di dimensione $150 \\times 200$ in cui l'intensità di ogni pixel è rappresentata da un byte ($[0;255]$ dove 0 rappresenta il nero e 255 il bianco)."
   ],
   "metadata": {
    "id": "rrpacUnRdXWn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "height=150\n",
    "width=200\n",
    "\n",
    "grayscale_image = np.zeros((height,width), np.uint8)\n",
    "\n",
    "print('Dimensione:',grayscale_image.shape)\n",
    "print('Formato:',grayscale_image.dtype)"
   ],
   "metadata": {
    "id": "e5735l0Mj456"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Visualizzare un'immagine**\n",
    "Per visualizzare un'immagine, OpenCV mette a disposizione la funzione **imshow(...)**. Questa funzione non può essere utilizzata su Colab per problemi di compatibilità. Al suo posto utilizzeremo la funzione **cv2_imshow(...)** disponibile nel package **google.colab.patches** (si veda import iniziale).\n",
    "\n",
    "Eseguendo la cella sottostante sarà possibile visualizzare l'immagine appena creata."
   ],
   "metadata": {
    "id": "cjwSlaqDheyj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cv2_imshow(grayscale_image)"
   ],
   "metadata": {
    "id": "HTMtXbMfg7GE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Accedere ai pixel di un'immagine**\n",
    "Essendo le immagini rappresentate come **ndarray**, è possibile accedere al valore di un singolo pixel di un’immagine utilizzando le parentesi quadre [riga, colonna].\n"
   ],
   "metadata": {
    "id": "BkYbZNvilA-w"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print('Valore di intensità del pixel in posizione [10,15]:',grayscale_image[10,15])"
   ],
   "metadata": {
    "id": "w-te26ehl12D"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inoltre, se si vuole accedere a una regione dell'immagine è possibile farlo in maniera semplice e intuitiva utilizzando lo *slicing* degli **ndarray**.\n",
    "\n",
    "La cella sottostante aggiorna l'intensità di tutti i pixel le cui coordinate di riga appartengono all'intervallo $[30;50[$ mentre quelle colonna ricadono nell'intervallo $[20;40[$ assegnadogli il valore 255 (bianco)."
   ],
   "metadata": {
    "id": "-ydTBclGl2hE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "grayscale_image[30:50,20:40]=255\n",
    "# slicing andrà a prendere la porzione della sottomatrice tra 30 e 50 escluso e\n",
    "# tutte le colonne dalla 20 alla 40 esclusa\n",
    "\n",
    "cv2_imshow(grayscale_image)"
   ],
   "metadata": {
    "id": "NGI2DaZ-g4SN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Salvare un'immagine**\n",
    "Un'immagine può essere salvata su disco tramite la funzione **imwrite(...)**."
   ],
   "metadata": {
    "id": "8GJKvSEcoBaO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "image_path='/content/myFirstOpenCVImage.png'\n",
    "\n",
    "cv2.imwrite(image_path,grayscale_image)"
   ],
   "metadata": {
    "id": "sRMtUYW_ndqP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verificare che il file contenente l'immagine appena salvata sia presente nel menù laterale **File**."
   ],
   "metadata": {
    "id": "XpQSMEJqd4Al"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Creare un'immagine a colori**\n",
    "La cella sottostante crea un'immagine a colori (con 3 canali) come una matrice 3D di dimensione $150 \\times 200 \\times 3$ in cui il colore di ogni pixel è rappresentato da 24 bit (3 byte)."
   ],
   "metadata": {
    "id": "CnFNopVDH8qa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "height=150\n",
    "width=200\n",
    "\n",
    "color_image = np.zeros((height,width,3), np.uint8)\n",
    "\n",
    "print('Dimensione:',color_image.shape)\n",
    "print('Formato:',color_image.dtype)\n",
    "\n",
    "cv2_imshow(color_image)"
   ],
   "metadata": {
    "id": "GDVnmkXsI_Uh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Ordine dei canali**\n",
    "Per ragioni storiche l’ordine dei canali non è RGB ma BGR.\n",
    "\n",
    "Eseguendo il codice contenuto nella cella sottostante, al primo canale dell'immagine a colori viene assegnato il valore 255. Come potete notare dall'immagine ottenuta, il primo canale corrisponde al colore blu (B) invece che al colore rosso (R) come ci saremmo aspettati.  "
   ],
   "metadata": {
    "id": "B6fx7tG1J7f5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Per ragioni storiche di retrocompatibilità non è RGB ma BGR.\n",
    "color_image[:,:,0]=255\n",
    "\n",
    "cv2_imshow(color_image)"
   ],
   "metadata": {
    "id": "73ltGukqKMWR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per poter convertire un'immagine da RGB a BGR (e vicecersa) è possibile utilizzare la funzione **cvtColor(...)** di OpenCV che, oltre all'immagine da convertire, prende in input il codice di conversione opportuno: COLOR_RGB2BGR (o COLOR_BGR2RGB)."
   ],
   "metadata": {
    "id": "HHnhpECRLHQo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bgr_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "cv2_imshow(bgr_image)"
   ],
   "metadata": {
    "id": "fGDUHCNXlRxi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In alternativa si possono utilizzare direttamente le funzionalità di slicing di NumPy. In questo caso è necessario utilizzare la funzione **copy(...)** altrimenti i dati sottostanti le due immagini rimarrebbero condivisi."
   ],
   "metadata": {
    "id": "8rHwmGHEM4vJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# senza la funzione copy genera una inversione in place e non genera una nuova istanza\n",
    "bgr_image =color_image[...,::-1].copy()\n",
    "\n",
    "cv2_imshow(bgr_image)"
   ],
   "metadata": {
    "id": "bsS9OhzMM963"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Caricare un'immagine**\n",
    "Un'immagine può essere caricata da disco tramite la funzione **imread(...)**.\n",
    "\n",
    "Come si può notare eseguendo la cella sottostante, la funzione restituisce un **ndarray** in cui il colore di ogni pixel è rappresentato da 3 byte (1 per ogni canale)."
   ],
   "metadata": {
    "id": "uk2ckcHOOIAT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "image_path='/content/Mexico.png'\n",
    "\n",
    "mexico_image=cv2.imread(image_path)\n",
    "\n",
    "print('Tipo di dato:',type(mexico_image))\n",
    "print('Dimensione:',mexico_image.shape)\n",
    "print('Formato:',mexico_image.dtype)\n",
    "\n",
    "cv2_imshow(mexico_image)"
   ],
   "metadata": {
    "id": "U0IOVt_SOW5u"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Elaborazione di immagini in OpenCV**\n",
    "OpenCV mette a disposizione numerose funzionalità per elaborare le immagini. Di seguito verranno illustrate alcune delle funzionalità più utilizzate."
   ],
   "metadata": {
    "id": "dblXbcpQTE9t"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Resize**\n",
    "È possibile ridimensionare un'immagine utilizzando la funzione **resize(...)** che, oltre all'immagine da ridimensionare, prende in input le dimensioni spaziali di output e il tipo di interpolazione da utilizzare (default: INTER_LINEAR)."
   ],
   "metadata": {
    "id": "e6MSK2pfUOq0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@interact(image=fixed(mexico_image),resize_factor=widgets.FloatSlider(min=0.1, max=3.0, step=0.1, value=1,continuous_update=False))\n",
    "def interactive_resize(image,resize_factor):\n",
    "  resized_h=int(image.shape[0]*resize_factor)\n",
    "  resized_w=int(image.shape[1]*resize_factor)\n",
    "  resized_image=cv2.resize(image,(resized_w,resized_h),cv2.INTER_LINEAR)\n",
    "  print('Dimensione:',resized_image.shape)\n",
    "  cv2_imshow(resized_image)"
   ],
   "metadata": {
    "id": "kRjJX_clWGoz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Rotazione**\n",
    "OpenCV mette a disposizione la funzione **rotate(...)** per ruotare un'immagine di un valore prefissato:\n",
    "- 90° in senso orario;\n",
    "- 90° in senso antiorario;\n",
    "- 180°."
   ],
   "metadata": {
    "id": "dXXXexxYXHpW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Rotazione esatta e precisa che non induce nessuna modifica dell'immagine\n",
    "@interact(image=fixed(mexico_image),rotate_code=widgets.Dropdown(options={'90° clockwise': cv2.ROTATE_90_CLOCKWISE, \\\n",
    "                                                                          '90° counterclockwise': cv2.ROTATE_90_COUNTERCLOCKWISE, \\\n",
    "                                                                          '180°': cv2.ROTATE_180},\n",
    "                                                                  value=cv2.ROTATE_90_CLOCKWISE,\n",
    "                                                                  description='Rotate code: '))\n",
    "def interactive_rotate(image,rotate_code):\n",
    "  rotated_image=cv2.rotate(image,rotate_code)\n",
    "  cv2_imshow(rotated_image)"
   ],
   "metadata": {
    "id": "BIQqVeTFX36K"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per poter ruotare un'immagine di un angolo a piacere, è necessario utilizzare in sequenta le funzioni:\n",
    "- **getRotationMatrix2D(...)** per ottere la matrice di rotazione da applicare all'immagine dati in input il centro di rotazione, l'agolo di rotazione e il fattore di scala (nel nostro caso costante a 1);\n",
    "- **warpAffine(...)** per applicare la trasformazione affine all'immagine da ruotare dati in input, oltre all'immagine, la matrice di rotazione e le dimensioni spaziali di output.\n",
    "\n",
    "La cella sottostante permette di ruotare un'immagine di un angolo a piacere nell'intervallo $]-180°;180]$ (con valori negativi la rotazione avviene in senso orario)."
   ],
   "metadata": {
    "id": "pCI2ow-XbCku"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rotation_center=(mexico_image.shape[1]/2,mexico_image.shape[0]/2)\n",
    "\n",
    "print('Coordinate del centro di rotazione:',rotation_center)\n",
    "\n",
    "@interact(image=fixed(mexico_image),rotation_center=fixed(rotation_center),rotation_angle=widgets.IntSlider(min=-179, max=180, step=1, value=0,continuous_update=False))\n",
    "def interactive_custom_rotate(image,rotation_center,rotation_angle):\n",
    "  rotation_matrix=cv2.getRotationMatrix2D(rotation_center,rotation_angle,1)\n",
    "  rotated_image = cv2.warpAffine(image,rotation_matrix,(image.shape[1],image.shape[0]))\n",
    "  cv2_imshow(rotated_image)"
   ],
   "metadata": {
    "id": "iWnLzNKybws5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Operatori logici**\n",
    "OpenCV mette a disposizione i 4 operatori logici di base (AND, OR, XOR e NOT) con cui è possibile eseguire operazioni di mascheratura su immagini binarie (l'intensità di ogni pixel può avere solo 2 valori:0=nero e 255=bianco).\n",
    "\n",
    "Per poter vedere alcuni esempi prima di tutto creiamo 2 immagini binarie.\n",
    "\n",
    "Utilizzando la funzione **rectangle(...)** è possibile disegnare un rettangolo all'interno di un'immagine."
   ],
   "metadata": {
    "id": "jt6W-FjVeJXh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rectangle_image = np.zeros((150, 200), dtype=\"uint8\")\n",
    "# si può fare anche con slicing\n",
    "cv2.rectangle(rectangle_image, (50, 25), (150, 125), 255, -1)\n",
    "\n",
    "print('Dimensione:',rectangle_image.shape)\n",
    "print('Formato:',rectangle_image.dtype)\n",
    "\n",
    "cv2_imshow(rectangle_image)"
   ],
   "metadata": {
    "id": "H5MiFLT6nK7a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In maniera analoga è possibile disegnare un cerchio utilizzando la funzione **circle(...)**."
   ],
   "metadata": {
    "id": "EV0JHPqFSmeb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "circle_image = np.zeros((150, 200), dtype = \"uint8\")\n",
    "cv2.circle(circle_image, (100, 75), 65, 255, -1)\n",
    "\n",
    "print('Dimensione:',circle_image.shape)\n",
    "print('Formato:',circle_image.dtype)\n",
    "\n",
    "cv2_imshow(circle_image)"
   ],
   "metadata": {
    "id": "qEg26WcGRKbE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **AND**\n",
    "La funzione **bitwise_and(...)** esegue l'operatore logico AND pixel a pixel tra le due immagini di input.\n",
    "Intersezione del quadrato e cerchio."
   ],
   "metadata": {
    "id": "YzbA7I52TWb6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bitwise_and_image=cv2.bitwise_and(rectangle_image,circle_image)\n",
    "\n",
    "print('Dimensione:',bitwise_and_image.shape)\n",
    "print('Formato:',bitwise_and_image.dtype)\n",
    "\n",
    "cv2_imshow(bitwise_and_image)"
   ],
   "metadata": {
    "id": "3lnMaDqzTXK7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **OR**\n",
    "La funzione **bitwise_or(...)** esegue l'operatore logico OR pixel a pixel tra le due immagini di input.\n",
    "Unione tra quadrato e cerchio"
   ],
   "metadata": {
    "id": "FU8qiPXbVW9J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bitwise_or_image=cv2.bitwise_or(rectangle_image,circle_image)\n",
    "\n",
    "print('Dimensione:',bitwise_or_image.shape)\n",
    "print('Formato:',bitwise_or_image.dtype)\n",
    "\n",
    "cv2_imshow(bitwise_or_image)"
   ],
   "metadata": {
    "id": "5K4w_Fz2Va5Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **XOR**\n",
    "La funzione **bitwise_xor(...)** esegue l'operatore logico XOR pixel a pixel tra le due immagini di input."
   ],
   "metadata": {
    "id": "ZeLT8YmVV46C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bitwise_xor_image=cv2.bitwise_xor(rectangle_image,circle_image)\n",
    "\n",
    "print('Dimensione:',bitwise_xor_image.shape)\n",
    "print('Formato:',bitwise_xor_image.dtype)\n",
    "\n",
    "cv2_imshow(bitwise_xor_image)"
   ],
   "metadata": {
    "id": "o8gaQAWPV-85"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **NOT**\n",
    "La funzione **bitwise_not(...)** esegue l'operatore logico NOT pixel a pixel sull'immagine di input.\n",
    "Si applica solo ad una immagine alla volta"
   ],
   "metadata": {
    "id": "eDEoMY-4WDWh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "not_image=cv2.bitwise_not(bitwise_xor_image)\n",
    "\n",
    "print('Dimensione:',not_image.shape)\n",
    "print('Formato:',not_image.dtype)\n",
    "\n",
    "cv2_imshow(not_image)"
   ],
   "metadata": {
    "id": "yMF4cUH3WTxZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Mascheratura**\n",
    "La funzione **bitwise_and(...)** può essere anche utilizzata per effettuare operazioni di mascheratura così da mantenere i soli pixel dell'immagine di input presenti nella maschera.\n",
    "\n",
    "Eseguendo la cella sottostante verrà eseguita l'operazione di mascheratura utilizzando come maschera il risultato dell'operatore XOR."
   ],
   "metadata": {
    "id": "JZHr0AFHYAzp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "masked = cv2.bitwise_and(mexico_image,mexico_image, mask=bitwise_xor_image)\n",
    "cv2_imshow(masked)"
   ],
   "metadata": {
    "id": "Z7J9ksz5deOq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Split e merge**\n",
    "In alcune circostanze può essere utile manipolare separatamente i singoli canali di una immagine a colori (o più in generale multi-canale).\n",
    "\n",
    "La funzione **split(...)** restituisce una lista contenente i vari canali che compongono l'immagine di input preservandone l'ordine."
   ],
   "metadata": {
    "id": "c1-JjF95cIBT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "b,g,r = cv2.split(mexico_image)\n",
    "\n",
    "print('B')\n",
    "print('Dimensione:',b.shape)\n",
    "cv2_imshow(b)\n",
    "\n",
    "print('G')\n",
    "print('Dimensione:',g.shape)\n",
    "cv2_imshow(g)\n",
    "\n",
    "print('R')\n",
    "print('Dimensione:',r.shape)\n",
    "cv2_imshow(r)"
   ],
   "metadata": {
    "id": "UIGY_ytTeuIj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In maniera speculare è possibile combinare più immagini a singolo canale in un'unica immagine multi-canale utilizzando la funzione **merge(...)**."
   ],
   "metadata": {
    "id": "cNzxrXhddUM-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "merged_image=cv2.merge([b,g,r])\n",
    "\n",
    "print('Dimensione:',merged_image.shape)\n",
    "cv2_imshow(merged_image)"
   ],
   "metadata": {
    "id": "n4UStsswdno8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Istogramma**\n",
    "L'istogramma di un'immagine è una delle feature colore più comuni. La funzione **calcHist(...)** restituisce l'istogramma dati in input l'immagine, il canale su cui calcolarlo e il numero di *bin* di cui sarà composto."
   ],
   "metadata": {
    "id": "4bnqE5IWYA-r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@interact(image=fixed(mexico_image),bin_count=widgets.IntSlider(min=5, max=256, step=1, value=256,continuous_update=False))\n",
    "def interactive_hist(image,bin_count):\n",
    "  for i,col in enumerate(['b','g','r']):\n",
    "      hist = cv2.calcHist([image],[i],None,[bin_count],[0,256])\n",
    "      plt.plot(hist,color = col)\n",
    "      plt.xlim([0,bin_count])\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "IrouvnI_YFp0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Esercizi**\n",
    "Implementare le seguenti operazioni utilizzando le funzionalità messe a disposizione da OpenCV e NumPy:\n",
    "1. ritagliare una porzione di immagine;\n",
    "2. binarizzare un'immagine grayscale utilizzando una soglia globale;\n",
    "3. variare la luminosità di un'immagine grayscale;\n",
    "4. effettuare il *flip* di un'immagine;\n",
    "5. applicare un filtro di *blurring* a una immagine grayscale;\n",
    "6. applicare un filtro di *sharpening* a una immagine grayscale.\n",
    "\n",
    "Eseguire tutte le operazioni sull'immagine caricata dalla cella di codice seguente.\n"
   ],
   "metadata": {
    "id": "qp40HW-Rer3k"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "china_image=cv2.imread('China4.png',cv2.COLOR_RGB2BGR)\n",
    "\n",
    "print('Tipo di dato:',type(china_image))\n",
    "print('Dimensione:',china_image.shape)\n",
    "print('Formato:',china_image.dtype)\n",
    "\n",
    "cv2_imshow(china_image)"
   ],
   "metadata": {
    "id": "iPE_giwoUJe-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Ritaglio**\n",
    "Ritagliare la porzione di immagine contenente la statua del drago utilizzando lo *slicing* degli **ndarray**."
   ],
   "metadata": {
    "id": "f1iDv4SQ-T7H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dragon_statue=cv2_imshow(china_image[140:,150:])"
   ],
   "metadata": {
    "id": "PcBhR3cnnTh6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Binarizzazione**\n",
    "Implementare la funzione **interactive_binarize(...)** che visualizza l'immagine di input binarizzata con la soglia globale *bin_thr*. Per effettuare la binarizzazione utilizzare la funzione **threshold(...)** di OpenCV."
   ],
   "metadata": {
    "id": "AD4PUnhD-col"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Tutto ciò che è sopra la binarizzazione è bianca, tutto ciò che è sotto nero\n",
    "@interact(image=fixed(china_image),bin_thr=widgets.IntSlider(min=0, max=255, step=1, value=128,continuous_update=False))\n",
    "def interactive_binarize(image,bin_thr):\n",
    "  _,bin_image= cv2.threshold(image, bin_thr, 255, cv2.THRESH_BINARY)\n",
    "  cv2_imshow(bin_image)"
   ],
   "metadata": {
    "id": "3eWJRRd-c2kW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Variazione della luminosità**\n",
    "Implementare la funzione **interactive_brightness(...)** che visualizza l'immagine di input dopo averne variato la luminosità in base al parametro *v*. l'intensità luminosa di un pixel dell'immagine di ouptut può essere calcolata come: $p'[y,x]=p[y,x]+v$.\n",
    "\n",
    "Per farlo, utilizzare le funzioni [**astype(...)**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html) e [**clip(...)**](https://numpy.org/doc/stable/reference/generated/numpy.clip.html) di NumPy."
   ],
   "metadata": {
    "id": "K_SjjSrg_J2R"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@interact(image=fixed(china_image),v=widgets.IntSlider(min=-255, max=255, step=1, value=0,continuous_update=False))\n",
    "def interactive_brightness(image,v):\n",
    "  modified_image = image.astype(np.int32)+v # convertiamo l'immagine perchè e senza segno e aggiungiamo v\n",
    "  brightness_image= np.clip(modified_image, 0,255) #clippiamo l'immagine a [0,255]\n",
    "  cv2_imshow(brightness_image)"
   ],
   "metadata": {
    "id": "DUQba-x_U48l"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Flip**\n",
    "Implementare la funzione **interactive_flip(...)** che visualizza l'immagine di input dopo averne fatto il flip in base al parametro *flip_code*. Per effettuare il flip utilizzare la funzione **flip(...)** di OpenCV."
   ],
   "metadata": {
    "id": "Db3JsdCm_g9Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@interact(image=fixed(china_image),flip_code=widgets.Dropdown(options={'Vertical': 0,'Horizontal': 1,'Both': -1},value=0,description='Flip: '))\n",
    "def interactive_flip(image,flip_code):\n",
    "  flipped_image = cv2.flip(image, flip_code)\n",
    "  cv2_imshow(flipped_image)"
   ],
   "metadata": {
    "id": "HRJRiirUWA7C"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Blurring**\n",
    "Implementare la funzione **interactive_blurring(...)** che visualizza il risultato dell'operazione di convoluzione tra l'immagine di input e un filtro omogeneo di dimensione *kernel_size*:\n",
    "\n",
    "<img src=https://biolab.csr.unibo.it/vr/esercitazioni/NotebookImages/EsIntroduzioneOpenCV\\HomogeneousBlurFilter.png width=\"150\">\n",
    "\n",
    "Per creare il filtro utilizzare la funzione [**ones(...)**](https://numpy.org/doc/stable/reference/generated/numpy.ones.html) di NumPy mentre per eseguire la convoluzione utilizzare la funzione **filter2D(...)** di OpenCV."
   ],
   "metadata": {
    "id": "5h_qZ-wZbOBQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@interact(image=fixed(china_image),kernel_size=widgets.IntSlider(min=3, max=15, step=2, value=3,continuous_update=False))\n",
    "def interactive_blurring(image,kernel_size):\n",
    "   blur_kernel = np.ones((kernel_size,kernel_size))/(kernel_size**2)\n",
    "  #  ddepth ci permette di dire il tipo di dato in output. Con -1\n",
    "  # di defaul è il formato più consono\n",
    "   blurred_image = cv2.filter2D(src=image, ddepth=-1, kernel=blur_kernel)\n",
    "   cv2_imshow(blurred_image)"
   ],
   "metadata": {
    "id": "ee8gbCvOYaO8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Sharpening**\n",
    "Eseguire l'operazione di convoluzione tra l'immagine di input e il seguente filtro di sharpening:\n",
    "\n",
    "<img src=https://biolab.csr.unibo.it/vr/esercitazioni/NotebookImages/EsIntroduzioneOpenCV\\SharpFilter.png width=\"120\">"
   ],
   "metadata": {
    "id": "h2kS2h9KbRNA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sharp_kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\n",
    "sharpered_image = cv2.filter2D(src=china_image, ddepth=cv2.CV_16S, kernel=sharp_kernel)\n",
    "print(sharpered_image.dtype)\n",
    "sharpered_image = cv2.filter2D(src=china_image, ddepth=-1, kernel=sharp_kernel)\n",
    "print(sharpered_image.dtype)\n",
    "cv2_imshow(sharpered_image)"
   ],
   "metadata": {
    "id": "jDFp-NcEailW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "        # **Machine learning in OpenCV**\n",
    "Il modulo **ml** di OpenCV mette a disposizione una serie di classi per l'utilizzo di algoritmi di *machine learning* tra cui:\n",
    "- KNearest;\n",
    "- NormalBayesClassifier;\n",
    "- SVM.\n",
    "\n",
    "Tutte queste classi implementano la stessa interfaccia che espone i seguenti metodi:\n",
    "- *train* - per l'addestramento del modello;\n",
    "- *predict* - per predire la classe di un determinato input;\n",
    "- *save* - per salvare un modello;\n",
    "- *load* - per caricare un modello precedentemente salvato.\n"
   ],
   "metadata": {
    "id": "ncehKEFHiByN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Creazione dei dataset**\n",
    "Prima di poter utilizzare le classi sopra citate, è necessario avere a disposizione un dataset di training con cui addestrare il modello e uno di test per valutarne le prestazioni.\n",
    "\n",
    "Le istruzioni contenute nella cella sottostante utilizzano la funzione [**normal(...)**](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html) del modulo **random** di NumPy per creare:\n",
    "- un dataset di training composto da *pattern* bi-dimensionali appartenenti a 3 classi derivate da 3 differenti distribuzioni normali;\n",
    "- un dataset di test composto da *pattern* bi-dimensionali da classificare."
   ],
   "metadata": {
    "id": "-ukt4vmVjPN9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_count_per_class=200\n",
    "test_count=10\n",
    "\n",
    "train_x0=np.random.normal((100,100),25,(train_count_per_class,2)).astype(np.float32)\n",
    "train_y0=np.zeros((train_count_per_class,),np.int32)\n",
    "\n",
    "train_x1=np.random.normal((300,100),25,(train_count_per_class,2)).astype(np.float32)\n",
    "train_y1=np.ones((train_count_per_class,),np.int32)\n",
    "\n",
    "train_x2=np.random.normal((200,200),25,(train_count_per_class,2)).astype(np.float32)\n",
    "train_y2=np.ones((train_count_per_class,),np.int32)+1\n",
    "\n",
    "test_x=np.random.normal((200,125),50,(test_count,2)).astype(np.float32)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(train_x0[:,0],train_x0[:,1],s=3,c='r',label='0')\n",
    "plt.scatter(train_x1[:,0],train_x1[:,1],s=3,c='b',label='1')\n",
    "plt.scatter(train_x2[:,0],train_x2[:,1],s=3,c='g',label='2')\n",
    "plt.scatter(test_x[:,0],test_x[:,1],c='gray',marker='x',label='Unknown')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "ENm7wnLItHxd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le feature (e le corrispondenti *label*) vengono unite a formare il training set utilizzando la funzione [**concatenate(...)**](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html) di NumPy."
   ],
   "metadata": {
    "id": "KpOzVzzDlmOd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_x=np.concatenate((train_x0,train_x1,train_x2),axis=0)\n",
    "train_y=np.concatenate((train_y0,train_y1,train_y2),axis=0)\n",
    "\n",
    "print('Dimensione delle feature del training set:',train_x.shape)\n",
    "print('Dimensione delle label del training set:',train_y.shape)"
   ],
   "metadata": {
    "id": "XiWpA2qNxKWV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **K-nearest neighbor**\n",
    "In questa sezione addestreremo un *K-nearest-neighbor* sul training set appena creato per poi classificare i *pattern* del test set."
   ],
   "metadata": {
    "id": "pi3epGJ4mRPx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Creazione**\n",
    "Per creare un'istanza della classe **KNearest** è sufficiente utilizzare la sua funzione statica **create(...)**.\n",
    "\n",
    "Il metodo **setDefaultK(...)** può essere richiamato per impostare il numero di vicini (*k*) da prendere in considerazione per classificare un nuovo *pattern*."
   ],
   "metadata": {
    "id": "VrQmHInHRdVa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "k=3\n",
    "\n",
    "knn=cv2.ml.KNearest.create()\n",
    "knn.setDefaultK(k)"
   ],
   "metadata": {
    "id": "qnmvvIzDwb7O"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Addestramento**\n",
    "Per addestrare l'istanza appena creata è sufficiente richiamare il metodo **train(...)** passandogli, oltre alle *feature* e le *label* di training, il *layout* dei dati passati (ROW_SAMPLE=memorizzati per righe, COL_SAMPLE=memorizzati per colonne)."
   ],
   "metadata": {
    "id": "ha1XtqOFAqhL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "knn.train(train_x,cv2.ml.ROW_SAMPLE,train_y)"
   ],
   "metadata": {
    "id": "2Ro9e4w1Araj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Prediction**\n",
    "Il metodo **predict(...)** permette di predire le classi di appartenenza dei *pattern* passati in input."
   ],
   "metadata": {
    "id": "BQJcRiJgm4TL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "_,results=knn.predict(test_x)\n",
    "\n",
    "print('Dimensione delle predizioni sul test set:',results.shape)\n",
    "print(results)"
   ],
   "metadata": {
    "id": "3FrqKnf1zL3N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Salvataggio**\n",
    "Il salvataggio di un modello addestrato è fondamentale per poterlo utilizzare successivamente o su un altro dispositivo.\n",
    "\n",
    "Con il metodo **save(...)** è possibile salvare l'istanza del *K-nearest neighbor* appena addestrato."
   ],
   "metadata": {
    "id": "8tQAOfxvm5p5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "knn.save('knnModel.txt')"
   ],
   "metadata": {
    "id": "W-ZZ4gMr1r9W"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verificare che il file contenente il modello appena salvato sia presente nel menù laterale **File**."
   ],
   "metadata": {
    "id": "trytLfq5RPFy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Caricamento**\n",
    "Per poter caricare un modello salvato in precedenza è sufficiente utilizzare il metodo statico **load(...)** della classe corrispondente."
   ],
   "metadata": {
    "id": "lXRosg3GSFgK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loaded_knn=cv2.ml.KNearest.load('knnModel.txt')\n",
    "\n",
    "_,results=loaded_knn.predict(test_x)\n",
    "\n",
    "print('Dimensione delle predizioni sul test set:',results.shape)\n",
    "print(results)"
   ],
   "metadata": {
    "id": "rzgnX0H8SZ_R"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Come potete vedere la classificazione del test set è identica a quella svolta in precedenza a conferma che il modello caricato è uguale a quello precedente."
   ],
   "metadata": {
    "id": "1Jsa5GStSp6Z"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Esercizi**\n",
    "Addestrare i seguenti classificatori sul training set creato e classificare i *pattern* del test set:\n",
    "1. NormalBayesClassifier;\n",
    "2. SVM."
   ],
   "metadata": {
    "id": "vK5oCW2sm737"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **NormalBayesClassifier**\n",
    "Per classificare il test set utilizzando il classificatore di *Bayes*, è sufficiente creare e addestrare un'istanza della classe **NormalBayesClassifier** utilizzando i metodi **create(...)** e **train(...)** per poi richiamare il metodo **predict(...)**."
   ],
   "metadata": {
    "id": "fBQGVdNYm98p"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "nbc = cv2.ml.NormalBayesClassifier.create()\n",
    "nbc.train(train_x, cv2.ml.ROW_SAMPLE, train_y)\n",
    "_,results = svm.predict(test_x)\n",
    "print(results)\n",
    "nbc.save('nbcModel.txt')"
   ],
   "metadata": {
    "id": "9GrBHD-UP6Fs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **SVM**\n",
    "Per classificare il test set utilizzando una *Support-Vector Machine*, è sufficiente creare e addestrare un'istanza della classe **SVM** utilizzando i metodi **create(...)** e **train(...)** per poi richiamare il metodo **predict(...)**.\n",
    "\n",
    "Attenzione: è necessario richiamare il metodo **setKernel(...)** per impostare il Kernel (es. SVM_LINEAR, SVM_POLY, SVM_RBF, SVM_SIGMOID) da utilizzare, prima di poter effettuare l'addestramento. In base al Kernel selezionato potrebbe essere necessario impostare specifici parametri (es. *C*, *gamma*, *coef*, *degree*, ecc.)."
   ],
   "metadata": {
    "id": "Mu7qyY_znO_7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "svm = cv2.ml.SVM.create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "\n",
    "svm.train(train_x,cv2.ml.ROW_SAMPLE,train_y)\n",
    "_,results=svm.predict(test_x)\n",
    "print(results)\n",
    "svm.save('svmModel.txt')"
   ],
   "metadata": {
    "id": "4h9tdFTXR8eW"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
